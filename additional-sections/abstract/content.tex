\newpage
\begin{center}
    \LARGE
    Context-Aware Speculative Decoding for \\Retrieval Augmented
Generation with a case study at UZGent \\
    
    \vspace{1cm}
    \large
    Gianni Van de Velde
    
    Supervisors: Prof. dr. ir. Thomas Demeester, Prof. dr. ir. Chris Develder
    
    Counsellor: CÃ©dric Goemaere
    
    Master's dissertation submitted in order to obtain the academic degree of\\
    Master of Science in Computer Science Engineering
    
    Ghent University
    
    Academic year 2024-2025
\end{center}

\vspace{0.5cm}
\begin{center}
    \textbf{\Large Abstract}
\end{center}

In recent years, Large Language Models (LLMs) have taken over the world, leading to spectacular applications but also concerns about their energy consumption. In an ideal world, the models would provide the same answers faster, while using less energy. This thesis works towards that ideal world. Speculative decoding is a proven method to increase time and energy efficiency for LLMs and this thesis builds further on the current state-of-the-art (SOTA) to achieve even more efficiency. We present Context-Aware Speculative Decoding (CASD), a hybrid method that can augment any other speculator to achieve better performance in high-copy environments. Retrieval-Augmented Generation (RAG) is a technique that is very popular in the business world and it yields such a high-copy environment. However, limited benchmarks are available for RAG and certainly in niche domains (e.g. medical, Dutch), where the SOTA underperforms. For this reason, we deliver a new benchmark UZGentRAG with data from a real world use case: RAG at UZGent. This benchmark not only proves the strength of CASD, but also the gap that current method seem to leave open. In the future, we expect CASD to become the standard augmentation method of speculative decoders in RAG uses cases, certainly in low-resource languages.

\begin{center}
    \textbf{\Large Keywords}
\end{center}
\begin{center}
    \{Speculative Decoding, RAG, LLM\}
\end{center}
